{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccaaa48-aff8-4460-96e2-3dc47e8497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルに記載したフォルダ・PDFファイル名を読み込み、\n",
    "# PDFファイルのテキストの属性情報をinfoフォルダに格納\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import fitz\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('/work_dir') \n",
    "import talknize_module_20240909 as tk\n",
    "import csv\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "\n",
    "# ログファイルの設定\n",
    "log_filename = \"data/logfile_attrib_info.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # ログレベルの設定 (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # ログのフォーマット\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, mode=\"a\", encoding=\"utf-8\"),  # ファイルに記録\n",
    "        #logging.StreamHandler()  # コンソールにも出力\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775e22d3-f10f-4027-8ae7-3085924d9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_attributes(pdf_path, page_number, output_csv_path):\n",
    "    \"\"\"\n",
    "    指定したPDFファイルのブロック・ライン・スパン単位でデータ属性を取得し、CSV形式で出力。\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): PDFファイルのパス。\n",
    "        page_number (int): ページ番号（1から始まる）。\n",
    "        output_csv_path (str): 出力するCSVファイルのパス。\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: 取得したデータ属性を保持するデータフレーム。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # PDFを開く\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        # ページ番号が正しいか確認\n",
    "        if page_number < 1 or page_number > len(doc):\n",
    "            print(f\"エラー: ページ番号が総ページ数{len(doc)}を超えています。最終ページを対象に処理を進めます。\")\n",
    "            logging.warning(f\"ページ番号が総ページ数{len(doc)}を超えています。最終ページを対象に処理を進めます。\")\n",
    "            page_number = len(doc)\n",
    "        \n",
    "        # 対象ページを取得（0インデックス）\n",
    "        page = doc[page_number - 1]\n",
    "        \n",
    "        # ページ内のブロックを取得\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        # データ保持用リスト\n",
    "        data = []\n",
    "        \n",
    "        for block_no, block in enumerate(blocks, start=1):\n",
    "            if \"lines\" not in block:\n",
    "                continue  # ブロックに行がない場合はスキップ\n",
    "            \n",
    "            for line_no, line in enumerate(block[\"lines\"], start=1):\n",
    "                if \"spans\" not in line:\n",
    "                    continue  # 行にスパンがない場合はスキップ\n",
    "                \n",
    "                for span_no, span in enumerate(line[\"spans\"], start=1):\n",
    "                    # 各スパンの属性を取得\n",
    "                    text = span.get(\"text\", \"\")\n",
    "                    bbox = line[\"bbox\"]\n",
    "                    font = span.get(\"font\", \"\")\n",
    "                    size = span.get(\"size\", \"\")\n",
    "                    color = span.get(\"color\", \"\")\n",
    "                    text_type = span.get(\"flags\", \"\")\n",
    "                    origin = span.get(\"origin\", (None, None))  # originを取得\n",
    "                    ascender = span.get(\"ascender\", None)      # ascenderを取得\n",
    "                    \n",
    "                    # データをリストに追加\n",
    "                    data.append({\n",
    "                        \"page_no\": page_number,\n",
    "                        \"block_no\": block_no,\n",
    "                        \"line_no\": line_no,\n",
    "                        \"span_no\": span_no,\n",
    "                        \"text\": text,\n",
    "                        \"origin_x\": origin[0],\n",
    "                        \"origin_y\": origin[1],\n",
    "                        \"bbox_x0\": bbox[0],\n",
    "                        \"bbox_y0\": bbox[1],\n",
    "                        \"bbox_x1\": bbox[2],\n",
    "                        \"bbox_y1\": bbox[3],\n",
    "                        \"font\": font,\n",
    "                        \"size\": size,\n",
    "                        \"color\": color,\n",
    "                        \"text_type\": text_type,\n",
    "                        \"ascender\": ascender,\n",
    "                    })\n",
    "        \n",
    "        # PDFを閉じる\n",
    "        doc.close()\n",
    "        \n",
    "        # pandasデータフレームに変換\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # CSVとして出力\n",
    "        df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "        #print(f\"ターゲットページの属性情報がCSVに出力されました: {output_csv_path}\")\n",
    "        logging.info(f\"ターゲットページの属性情報がCSVに出力されました: {output_csv_path}\")\n",
    "        return df\n",
    " \n",
    "    except Exception as e:\n",
    "        print(f\"extract_pdf_attributesでエラーが発生しました: {e}\")\n",
    "        logging.error(f\"extract_pdf_attributesでエラーが発生しました: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a707d3ee-e149-4d63-8fed-4149de57c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVを読み込む関数\n",
    "def load_csv(file_path):\n",
    "    \"\"\"\n",
    "    CSVを読み込み、DataFrameを返す\n",
    "    file_path: CSVファイルのパス\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {file_path}\")\n",
    "        logging.error(f\"Error: CSV file not found at {file_path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: CSV file at {file_path} is empty or invalid\")\n",
    "        logging.error(f\"Error: CSV file at {file_path} is empty or invalid\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        logging.error(f\"Error reading CSV file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0e5d2-dac7-4ccb-a0ba-361d952c5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全頁からブロックの属性情報を抽出・データフレームに格納\n",
    "\n",
    "def extract_blocks_from_pdf(pdf_path):\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "    data = []\n",
    "\n",
    "    # 各ページからデータ抽出\n",
    "    for page_num in range(len(pdf_doc)):\n",
    "        page = pdf_doc[page_num]\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            block_bbox = block[\"bbox\"]\n",
    "            for line in block.get(\"lines\", []):\n",
    "                line_text = \" \".join([span[\"text\"] for span in line[\"spans\"]])\n",
    "                line_bbox = line[\"bbox\"]\n",
    "                data.append({\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"x0\": line_bbox[0],\n",
    "                    \"y0\": line_bbox[1],\n",
    "                    \"x1\": line_bbox[2],\n",
    "                    \"y1\": line_bbox[3],\n",
    "                    \"text\": line_text.strip()\n",
    "                })\n",
    "    pdf_doc.close()\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918f384a-b954-44aa-8a64-54e93e98ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データフレームに格納された（全ページの）属性情報からヘッダ・フッタ候補を抽出、同一内容のものを集約し件数をカウント\n",
    "\n",
    "def identify_header_footer(data, threshold=40):\n",
    "    # ページごとの y0 値の分布を取得\n",
    "    headers = []\n",
    "    footers = []\n",
    "\n",
    "    for page_num, group in data.groupby(\"page\"):\n",
    "        y0_values = group[\"y0\"].values\n",
    "        if len(y0_values) == 0:\n",
    "            continue\n",
    "        y1_values = group[\"y1\"].values\n",
    "        if len(y1_values) == 0:\n",
    "            continue\n",
    "\n",
    "        min_y0, max_y0 = np.min(y0_values), np.max(y0_values)\n",
    "        min_y1, max_y1 = np.min(y1_values), np.max(y1_values)\n",
    "\n",
    "        # ヘッダ候補: y1 が分布の下位 (小さい値)\n",
    "        header_candidates = group[np.abs(group[\"y1\"] - min_y1) < threshold]\n",
    "        headers.append(header_candidates)\n",
    "\n",
    "        # フッタ候補: y0 が分布の上位 (大きい値)\n",
    "        footer_candidates = group[np.abs(group[\"y0\"] - max_y0) < threshold]\n",
    "        footers.append(footer_candidates)\n",
    "\n",
    "    # ヘッダ・フッタを統合\n",
    "    headers = pd.concat(headers, ignore_index=True)\n",
    "    footers = pd.concat(footers, ignore_index=True)\n",
    "\n",
    "    # 頻出パターンを確認 (x0, y0, text を基準にグループ化)\n",
    "    header_patterns = headers.groupby([\"x1\", \"y1\", \"text\"]).size().reset_index(name=\"count\")\n",
    "    footer_patterns = footers.groupby([\"x0\", \"y0\", \"text\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    return header_patterns, footer_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bc153c-081c-4e35-9c9c-a5379366f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Processing ir/2025/40610_デンカ/denkareport2024.pdf ====\n",
      "ir/2025/40610_デンカ/denkareport2024.pdfの処理が終了しました。\n"
     ]
    }
   ],
   "source": [
    "# メインルーチン\n",
    "\n",
    "def main():\n",
    "    # CSVファイルのパス\n",
    "    #csv_path = 'data/Attrib_Analysis_Target_20250114_test.csv'\n",
    "    #csv_path = 'data/Attrib_Analysis_Target_20250218.csv'\n",
    "    #csv_path = 'data/Attrib_Analysis_Target_20250218b.csv'\n",
    "    csv_path = 'data/Attrib_Analysis_Target_20250219_Denka.csv'  # CSVのパスを指定\n",
    "    \n",
    "\n",
    "    # CSVを読み込む\n",
    "    df_target = load_csv(csv_path)\n",
    "    if df_target is None:\n",
    "        print(\"Failed to load CSV. Exiting program.\")\n",
    "        logging.error(\"Failed to load CSV. Exiting program.\")\n",
    "        return\n",
    "\n",
    "    # 必要な列名を指定\n",
    "    folder_col = '格納フォルダ'\n",
    "    file_col = '統合報告書PDF'\n",
    "    target_col = 'target_page'\n",
    "\n",
    "    # CSVに必要な列がなければエラー表示\n",
    "    if folder_col not in df_target.columns or file_col not in df_target.columns or target_col not in df_target.columns:\n",
    "        print(f\"Error: CSV file must contain '{folder_col}' and '{file_col}' and '{target_page}' columns\")\n",
    "        logging.error(f\"Error: CSV file must contain '{folder_col}' and '{file_col}' and '{target_page}' columns\")\n",
    "        return\n",
    "\n",
    "    # リストの企業ごとに、ターゲットページ（のみ）の属性情報を取得・処理・保存\n",
    "    #file_paths = []\n",
    "    for index, row in df_target.iterrows():\n",
    "\n",
    "        #================================================================\n",
    "        #前処理（フォルダの確認・パス名の定義　等）\n",
    "        folder_name = 'ir/2025/' + row[folder_col]\n",
    "        file_name = row[file_col]\n",
    "        target_page = row[target_col]\n",
    "\n",
    "        # パスが有効かチェック\n",
    "        #　file_pathを作成してfile_pathsにリストとして追記・保存するが、必要情報がない場合は''としておく\n",
    "        if pd.isna(folder_name) or pd.isna(file_name):\n",
    "            print(f\"Skipping row {index}: Folder or File is missing\")\n",
    "            logging.warning(f\"Skipping row {index}: Folder or File is missing\")\n",
    "            file_path =''\n",
    "            return\n",
    "\n",
    "        print(f\"==== Processing {folder_name}/{file_name} ====\")\n",
    "        logging.info(f\"==== Processing {folder_name}/{file_name} ====\")\n",
    "\n",
    "        #属性情報を格納するフォルダ（info）の有無を確認、なければ作成\n",
    "        info_file_path = folder_name + '/' + 'info'\n",
    "        if not os.path.exists(info_file_path):\n",
    "            os.makedirs(info_file_path)\n",
    "\n",
    "        #================================================================\n",
    "        #属性情報の保存・データフレームへの格納\n",
    "        # file_path（対象PDF）を生成 \n",
    "        file_path = folder_name + '/' + file_name\n",
    "        #file_path = os.path.join(folder_name, file_name)\n",
    "        #file_paths.append(file_path)\n",
    "\n",
    "        #属性情報を格納するcsvファイルのパスを作成\n",
    "        output_file_path = info_file_path + '/' +file_name[:len(file_name)-4] + \"_attrib_page\" + str(target_page) + \".csv\"\n",
    "\n",
    "        # 属性情報を抽出し、CSVfファイルに出力の上、以降の作業用にデータフレームdf_attribに格納\n",
    "        df_attrib = extract_pdf_attributes(file_path, target_page, output_file_path)\n",
    "        #print(df_attrib)\n",
    "    \n",
    "        #================================================================\n",
    "        #テキストボックスの始点座標のプロット（ブロック番号付き）\n",
    "        # line_no=1 のデータを抽出\n",
    "        plot_data = df_attrib\n",
    "\n",
    "        # bbox_x0 と bbox_y0 をプロット (Y軸を上下反転)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(plot_data['bbox_x0'], plot_data['bbox_y0'], alpha=0.7, s=10)\n",
    "        \n",
    "        # block_no を各点に表示\n",
    "        for x, y, block_no in zip(plot_data['bbox_x0'], plot_data['bbox_y0'], plot_data['block_no']):\n",
    "            plt.text(x, y, str(block_no), fontsize=8, ha='right', va='bottom')  # block_no をラベルとして表示\n",
    "        \n",
    "        plt.title('Scatter Plot of box_x0 vs bbox_y0 with block_no', fontsize=14)\n",
    "        plt.xlabel('bbox_x0', fontsize=12)\n",
    "        plt.ylabel('bbox_y0 (Inverted)', fontsize=12)\n",
    "        plt.gca().invert_yaxis()  # Y軸を上下反転\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # プロットを保存\n",
    "        plot_file_path = info_file_path + '/' +file_name[:len(file_name)-4] + '_' +str(target_page) + \".png\"\n",
    "        # DPIを設定し保存\n",
    "        plt.savefig(plot_file_path, dpi=300, bbox_inches='tight')  \n",
    "        # プロットを表示\n",
    "        #plt.show()\n",
    "        # プロットを閉じる（これにより画面に表示されない）\n",
    "        plt.close()\n",
    "        #print(f\"プロットが保存されました: {plot_file_path}\")\n",
    "        logging.info(f\"プロットが保存されました: {plot_file_path}\")\n",
    "\n",
    "        #================================================================\n",
    "        #　上下左右のマージン検討・設定時に参照するブロックのxy座標及びテキスト情報をファイルに格納\n",
    "\n",
    "        n_write = 40\n",
    "        print_flag = False\n",
    "\n",
    "        # ヘッダ候補（y1）・フッタ候補（y0）.・左マージン候補（x0）・右マージン候補（x1）を作成\n",
    "        sorted_y1 = df_attrib.sort_values(by='bbox_y1', ascending=True)[['block_no', 'bbox_y1', 'text']]\n",
    "        sorted_y0 = df_attrib.sort_values(by='bbox_y0', ascending=False)[['block_no', 'bbox_y0', 'text']]\n",
    "        sorted_x1 = df_attrib.sort_values(by='bbox_x1', ascending=True)[['block_no', 'bbox_x1', 'text']]\n",
    "        sorted_x0 = df_attrib.sort_values(by='bbox_x0', ascending=False)[['block_no', 'bbox_x0', 'text']]\n",
    "\n",
    "        #画面表示用\n",
    "        if print_flag == True:\n",
    "            print(\"=== bbox(y1) for Header ===\")\n",
    "            print(sorted_y1)\n",
    "            print()\n",
    "            print(\"=== bbox(y0) for Footer ===\")\n",
    "            print(sorted_y0)\n",
    "            print()\n",
    "            print(\"=== bbox(x0) for Left Margin ===\")\n",
    "            print(sorted_x0)\n",
    "            print()\n",
    "            print(\"=== bbox(x0) for Right Margin ===\")\n",
    "            print(sorted_x1)\n",
    "        \n",
    "        output_file_path = info_file_path  + \"/\" + \"Margin_Candidate_list_page-\" + str(target_page) + \".txt\"\n",
    "        \n",
    "        # ヘッダ候補（y1）・フッタ候補（y0）.・左マージン候補（x0）・右マージン候補（x1）をテキストファイルに書き出す\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(\"=== bbox(y1) for Header ===\\n\")\n",
    "            for _, row in sorted_y1.head(n_write).iterrows():\n",
    "                # 'text'列を左寄せに整形して保存\n",
    "                file.write(f\"{row['block_no']}\\t{row['bbox_y1']:.2f}\\t{row['text']}\\n\")\n",
    "            file.write(\"\\n\\n\")  \n",
    "            file.write(\"=== bbox(y0) for Footer ===\\n\")\n",
    "            for _, row in sorted_y0.head(n_write).iterrows():\n",
    "                # 'text'列を左寄せに整形して保存\n",
    "                file.write(f\"{row['block_no']}\\t{row['bbox_y0']:.2f}\\t{row['text']}\\n\")\n",
    "            file.write(\"\\n\\n\")  \n",
    "            file.write(\"=== bbox(x0) for Left Margin ===\\n\")\n",
    "            for _, row in sorted_x1.head(n_write).iterrows():\n",
    "                # 'text'列を左寄せに整形して保存\n",
    "                file.write(f\"{row['block_no']}\\t{row['bbox_x1']:.2f}\\t{row['text']}\\n\")\n",
    "            file.write(\"\\n\\n\")  \n",
    "            file.write(\"=== bbox(x0) for Right Margin ===\\n\")\n",
    "            for _, row in sorted_x0.head(n_write).iterrows():\n",
    "                # 'text'列を左寄せに整形して保存\n",
    "                file.write(f\"{row['block_no']}\\t{row['bbox_x0']:.2f}\\t{row['text']}\\n\")\n",
    "\n",
    "        #=============================================\n",
    "        #以降はターゲットページのみではなく、各社の全頁からデータ取得、候補情報を集計\n",
    "        #全頁を読み込み、処理するため、かなり負荷がかかるはず\n",
    "        # PDFデータを抽出\n",
    "        df_pdf_all_pages = extract_blocks_from_pdf(file_path)\n",
    "    \n",
    "        # ヘッダ・フッタを識別\n",
    "        headers, footers = identify_header_footer(df_pdf_all_pages)\n",
    "    \n",
    "        # 結果をソートして表示\n",
    "        headers_sorted = headers.sort_values(\"y1\", ascending=True)\n",
    "        footers_sorted = footers.sort_values(\"y0\", ascending=True)\n",
    "    \n",
    "        #print(\"Identified Header Patterns:\")\n",
    "        #print(headers_sorted)\n",
    "        #print()\n",
    "        #print(\"Identified Footer Patterns:\")\n",
    "        #print(footers_sorted)\n",
    "    \n",
    "        # ソート済み結果をCSVに保存\n",
    "        output_header_path = info_file_path + \"/\" + \"header_candidates.csv\"\n",
    "        output_footer_path = info_file_path + \"/\" + \"footer_candidates.csv\"\n",
    "        headers_sorted.to_csv(output_header_path, index=False, encoding=\"utf-8-sig\")\n",
    "        footers_sorted.to_csv(output_footer_path, index=False, encoding=\"utf-8-sig\")\n",
    "        #print(f\"ヘッダ・フッタ候補の統計情報が保存されました: header_candidates.csv, footer_candidates.csv\")\n",
    "        logging.info(f\"ヘッダ・フッタ候補の統計情報が保存されました: header_candidates.csv, footer_candidates.csv\")\n",
    "\n",
    "        #=============================================\n",
    "        #テキスト取得時に参照するmargin.csvファイルを作成\n",
    "        #既に存在する場合はスキップ（書き込み情報の上書き防止のため）\n",
    "         #margin.csvが存在しない場合には、ブランクのcsvを書き込み\n",
    "        # チェックと生成\n",
    "        margin_info_path = info_file_path + \"/\" + \"margin.csv\"\n",
    "        if not os.path.exists(margin_info_path):\n",
    "            # データを作成 (全てNone)\n",
    "            margin_init = {\n",
    "                \"header_y\": [None],\n",
    "                \"footer_y\": [None],\n",
    "                \"left_margin_x\": [None],\n",
    "                \"right_margin_x\": [None]\n",
    "            }\n",
    "            df_margin = pd.DataFrame(margin_init)\n",
    "            # CSVファイルを保存\n",
    "            df_margin.to_csv(margin_info_path, index=False)\n",
    "            #print(f\"{margin_info_path} を新新規作成しました。\")\n",
    "            logging.info(f\"{margin_info_path} を新規作成しました。\")\n",
    "\n",
    "        else:\n",
    "            #print(f\"{margin_info_path} は既に存在しています。\")    \n",
    "            logging.warning(f\"{margin_info_path} は既に存在しています。\")    \n",
    "\n",
    "        #=============================================\n",
    "        #テキスト取得時に参照する multicolumn.txtファイルを作成\n",
    "        #既に存在する場合はスキップ（書き込み情報の上書き防止のため）\n",
    "        # multicolumn.txtが存在しない場合には、ブランクのtxtを書き込み\n",
    "        # チェックと生成\n",
    "        multicolumn_info_path = info_file_path + \"/\" + \"multicolumn.txt\"\n",
    "        if not os.path.exists(multicolumn_info_path):\n",
    "            # 空のテキストファイルを作成\n",
    "            with open(multicolumn_info_path,\"w\"):pass\n",
    "            logging.info(f\"{multicolumn_info_path} を新規作成しました。\")\n",
    "        else:\n",
    "            logging.warning(f\"{multicolumn_info_path} は既に存在しています。\")    \n",
    "\n",
    "        \n",
    "        print(f\"{file_path}の処理が終了しました。\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#順に企業コード・企業名・PDFファイル名を取り込み\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd7347-e978-46d5-a361-0ec9e79e24fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
