{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90842ae-613f-4a4c-add2-3fb2a405ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#テキストの属性をもとに段落を判別しつつテキストデータを取得\n",
    "#ヘッダ・フッタ等をテキストブロックの属性情報（特に位置情報）で除外\n",
    "#テキストを取得する範囲も、テキストブロックの開始位置の座標情報をもとに、強制的に読み込み順序を制御\n",
    "#（リスト形式で、x軸の閾値＝段組みの境界線を設定：ブランクのリストであればブロック・リストの順番通りに読み込み）\n",
    "#各ブロック・リストの座標の分布は、Extract_Pdf_Attrib.ipynbで確認可能\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('/work_dir') \n",
    "import csv\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "import html\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.sax.saxutils as saxutils  # XMLのエスケープ処理\n",
    "import re\n",
    "from xml.dom import minidom  # XML整形用\n",
    "\n",
    "# ログファイルの設定\n",
    "log_filename = \"data/logfile_Pdf2Txt.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # ログレベルの設定 (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",  # ログのフォーマット\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, mode=\"a\", encoding=\"utf-8\"),  # ファイルに記録\n",
    "        #logging.StreamHandler()  # コンソールにも出力\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4652a1d4-d212-4669-b598-4e93ce554ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVを読み込む関数\n",
    "def load_csv(file_path):\n",
    "    \"\"\"\n",
    "    CSVを読み込み、DataFrameを返す\n",
    "    file_path: CSVファイルのパス\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {file_path}\")\n",
    "        logging.error(f\"Error: CSV file not found at {file_path}\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: CSV file at {file_path} is empty or invalid\")\n",
    "        logging.error(f\"Error: CSV file at {file_path} is empty or invalid\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        logging.error(f\"Error reading CSV file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a842c9-2ba1-41ff-83cd-be5560a4ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_by_attributes(page, header_y, footer_y, left_margin_x, right_margin_x, column_thresholds, line_spacing_factor):\n",
    "    \"\"\"\n",
    "    指定されたページのテキストを、指定したヘッダー・フッター・マージンの範囲外を除外しながら整形する。\n",
    "    - ヘッダー、フッター、左右マージンを考慮し、不要なテキストを除去。\n",
    "    - 複数列のテキストを適切に処理する。\n",
    "    - フォントサイズに応じて適切な行間を設定し、改行を挿入。\n",
    "    - XMLエスケープ処理を行う。\n",
    "    \"\"\"\n",
    "    text = \"\"  # 抽出されたテキストを格納する変数\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]  # ページからテキストブロックを取得\n",
    "\n",
    "    def get_range_index(x0, ranges):\n",
    "        \"\"\" 指定された x0 座標がどのカラム範囲に属するかを判定 \"\"\"\n",
    "        for i, bound in enumerate(ranges):\n",
    "            if x0 < bound:\n",
    "                return i\n",
    "        return len(ranges)  # 範囲外は最後の区分として扱う\n",
    "\n",
    "    # `column_thresholds` が None の場合は空のリストに初期化\n",
    "    if column_thresholds is None:\n",
    "        column_thresholds = []\n",
    "\n",
    "    # 列ごとにテキストブロックを分類する辞書を初期化\n",
    "    sorted_blocks = {i: [] for i in range(len(column_thresholds) + 1)}\n",
    "\n",
    "    # 各テキストブロックを処理\n",
    "    for block_index, block in enumerate(blocks):\n",
    "        if \"lines\" not in block or not block[\"lines\"]:\n",
    "            continue  # 空のブロックをスキップ\n",
    "        for line_index, line in enumerate(block[\"lines\"]):\n",
    "            if not line[\"spans\"]:\n",
    "                continue  # 空の行をスキップ\n",
    "            line_bbox_x0 = line[\"spans\"][0][\"bbox\"][0]  # 行の最初のスパンのX座標を取得\n",
    "            range_index = get_range_index(line_bbox_x0, column_thresholds)  # カラムを判定\n",
    "            sorted_blocks.setdefault(range_index, []).append((block_index, block, line))  # カテゴリごとに分類\n",
    "\n",
    "    # 各範囲のブロックを処理\n",
    "    previous_font = None\n",
    "    previous_size = None\n",
    "    previous_color = None\n",
    "    previous_bbox = None\n",
    "    previous_text_type = None\n",
    "\n",
    "    # `line_spacing_factor` が None の場合、デフォルト値を設定\n",
    "    if line_spacing_factor is None:\n",
    "        line_spacing_factor = 2\n",
    "\n",
    "    for range_index, blocks in sorted_blocks.items():  # カラムごとに処理\n",
    "        for block_index, block, line in blocks:\n",
    "            for span in line[\"spans\"]:\n",
    "                bbox = span[\"bbox\"]  # テキストの座標情報\n",
    "                content = span[\"text\"]  # 実際のテキスト内容\n",
    "                font = span[\"font\"]  # フォント情報\n",
    "                size = span[\"size\"]  # 文字サイズ\n",
    "                color = span[\"color\"]  # 文字色\n",
    "                text_type = span.get(\"text_type\", \"text\")  # 文字種別\n",
    "\n",
    "                # 指定されたヘッダー・フッター・マージンの範囲外を除外\n",
    "                if bbox[3] is not None and header_y is not None and bbox[3] < header_y:\n",
    "                    continue\n",
    "                if bbox[1] is not None and footer_y is not None and bbox[1] > footer_y:\n",
    "                    continue\n",
    "                if bbox[2] is not None and left_margin_x is not None and bbox[2] < left_margin_x:\n",
    "                    continue\n",
    "                if bbox[0] is not None and right_margin_x is not None and bbox[0] > right_margin_x:\n",
    "                    continue\n",
    "\n",
    "                # 行間の閾値をフォントサイズに基づいて設定\n",
    "                line_threshold = size * line_spacing_factor\n",
    "\n",
    "                # 前の行との行間を比較し、新しい段落とみなすか判定\n",
    "                if (\n",
    "                    (previous_bbox and abs(bbox[3] - previous_bbox[3]) > line_threshold) or\n",
    "                    previous_text_type != text_type\n",
    "                ):\n",
    "                    text += \"\\n\\n\"  # 新しい段落を開始\n",
    "                else:\n",
    "                    text += \"\"  # 既存の段落に追加\n",
    "\n",
    "                # 不要なスペースの削除\n",
    "                content = re.sub(r\" \\n\", \"\\n\", content)  # 行末の半角スペースを削除\n",
    "                content = re.sub(r\"^ \", \"\", content)  # 行頭のスペースを削除\n",
    "\n",
    "                text += content  # 整形済みテキストを追加\n",
    "\n",
    "                # 前の状態を更新\n",
    "                previous_font = font\n",
    "                previous_size = size\n",
    "                previous_color = color\n",
    "                previous_bbox = bbox\n",
    "                previous_text_type = text_type\n",
    "\n",
    "    # 余分な改行を調整\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "\n",
    "    # XML/HTML特殊文字のエスケープ処理\n",
    "    escaped_text = html.escape(text)\n",
    "\n",
    "    return escaped_text  # 整形されたテキストを返す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6068feee-3fdd-4ba2-a13e-0780228c884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 目次データをCSVから読み込む\n",
    "def load_toc_mapping(csv_path):\n",
    "    df = pd.read_csv(csv_path)  # \"page\" 列に開始ページ, \"keyword\" 列にタグ\n",
    "    return df.sort_values(by=\"page\").reset_index(drop=True)\n",
    "\n",
    "# 2. PDFからページごとのテキストを抽出\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = {}\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        text = doc[page_num].get_text(\"text\")\n",
    "        text = clean_text(text)  # テキストのクリーンアップ（エンコード, 制御文字削除）\n",
    "        extracted_text[page_num + 1] = text\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "# 3. 特殊文字をエスケープ & 制御文字を削除\n",
    "def clean_text(text):\n",
    "    # 制御文字（不可視文字）を削除\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', '', text)\n",
    "\n",
    "    # XMLで問題になる特殊文字をエスケープ (&, <, >)\n",
    "    text = saxutils.escape(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# 4. 目次キーワードをページごとに適用\n",
    "def assign_tags_from_csv(extracted_text, toc_mapping):\n",
    "    \"\"\"\n",
    "    抽出されたPDFのテキストデータに対して、CSVで指定された目次キーワードを適用し、\n",
    "    各ページに対応するタグを付与する。\n",
    "    \n",
    "    - 同じページに複数のキーワードが存在する場合、元の `toc_mapping` の順序を維持して格納する。\n",
    "    - 目次データのページ範囲を考慮し、次の見出しが始まる前まで適用。\n",
    "    - `toc_mapping` に記載のないページには、直前のページのタグを適用する。\n",
    "    \n",
    "    Parameters:\n",
    "        extracted_text (dict): {ページ番号: テキスト} の辞書\n",
    "        toc_mapping (DataFrame): 目次データ（'page'列と'keyword'列を含む）\n",
    "    \n",
    "    Returns:\n",
    "        dict: {ページ番号: {\"text\": テキスト, \"tag\": [キーワード]}} の辞書\n",
    "    \"\"\"\n",
    "    tagged_data = {}  # タグ付けされたデータを格納する辞書\n",
    "    pages = sorted(extracted_text.keys())  # ページ番号をソート\n",
    "\n",
    "    # `page` 列を整数型に変換\n",
    "    toc_mapping[\"page\"] = toc_mapping[\"page\"].astype(int)\n",
    "    \n",
    "    # `toc_mapping` の順序を維持したまま、ページごとのキーワードリストを作成\n",
    "    sorted_toc = toc_mapping.sort_values(by=[\"page\"], ascending=True)\n",
    "    sorted_pages = sorted_toc[\"page\"].tolist()  # 目次のページリスト\n",
    "    prev_tags = []  # 直前のタグを保持するリスト\n",
    "    \n",
    "    for page_num in pages:  # すべてのページに対して処理\n",
    "        if page_num in sorted_pages:\n",
    "            # `toc_mapping` に記載があるページはそのキーワードを取得\n",
    "            prev_tags = sorted_toc.loc[sorted_toc[\"page\"] == page_num, \"keyword\"].dropna().tolist()\n",
    "        \n",
    "        if not prev_tags:\n",
    "            prev_tags = [\"unknown\"]  # どのタグも適用されていない場合、'unknown' を設定\n",
    "        \n",
    "        tagged_data[page_num] = {\"text\": extracted_text[page_num], \"tag\": prev_tags.copy()}  # タグをリストとして格納\n",
    "        #logging.info(f\"Page {page_num}: Assigned tags {prev_tags}\")\n",
    "    \n",
    "    return tagged_data  # タグ付けされたデータを返す\n",
    "\n",
    "    \n",
    "# 5. XMLを生成（タグの順序変更 + 可読性向上）\n",
    "def create_pretty_xml(tagged_data, output_file):\n",
    "    \"\"\"\n",
    "    タグ付けされたデータをXML形式で出力し、適切に整形する。\n",
    "    \n",
    "    Parameters:\n",
    "        tagged_data (dict): {ページ番号: {\"text\": テキスト, \"tag\": [キーワード]}} の辞書\n",
    "        output_file (str): 出力するXMLファイルのパス\n",
    "    \"\"\"\n",
    "    root = ET.Element(\"document\")\n",
    "\n",
    "    for page_num, data in tagged_data.items():\n",
    "        page_elem = ET.SubElement(root, \"page\", number=str(page_num))\n",
    "\n",
    "        tag_elem = ET.SubElement(page_elem, \"tag\")\n",
    "        tag_elem.text = \", \".join(data[\"tag\"]) if isinstance(data[\"tag\"], list) else \"Unknown\"  # タグをカンマ区切りで結合\n",
    "\n",
    "        content_elem = ET.SubElement(page_elem, \"content\")\n",
    "        content_elem.text = f\"<![CDATA[{data['text']}]]>\" if isinstance(data[\"text\"], str) else \"\"\n",
    "\n",
    "    rough_string = ET.tostring(root, encoding=\"utf-8\")\n",
    "\n",
    "    try:\n",
    "        parsed_xml = minidom.parseString(rough_string)\n",
    "        pretty_xml = parsed_xml.toprettyxml(indent=\"  \")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"XML Parsing Error: {e}\")\n",
    "        pretty_xml = rough_string.decode(\"utf-8\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(line for line in pretty_xml.split(\"\\n\") if line.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275688e7-516e-4643-b87d-549ee18c539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ir/2025/79360_アシックス_2022/アシックス統合報告書2022.pdf\n",
      "処理が終了しました。\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    #実行モードを設定\n",
    "    #複数企業の情報をcsvから読み込んで一括処理する場合、特定の企業のみ処理する場合を選択\n",
    "    #0:ファイルから読込、1:直接指定\n",
    "    Process_Mode=1 \n",
    "\n",
    "    if Process_Mode == 0:\n",
    "        # CSVファイルのパスを指定\n",
    "        #csv_path = 'data/Attrib_Analysis_Target_20250114_test.csv'  # CSVのパスを指定\n",
    "        #csv_path = 'data/Attrib_Analysis_Target_20250219_Denka.csv'  # CSVのパスを指定\n",
    "        csv_path = 'data/Attrib_Analysis_Target_20250228_temp.csv'  # CSVのパスを指定\n",
    "\n",
    "        # 統合報告書がリストされたCSVを読み込む\n",
    "        df_target = load_csv(csv_path)\n",
    "        if df_target is None:\n",
    "            print(\"Failed to load CSV. Exiting program.\")\n",
    "            logging.error(\"Failed to load CSV. Exiting program.\")\n",
    "            return\n",
    "\n",
    "    elif Process_Mode ==1:\n",
    "        #=========================================================================================\n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        #単独処理：格納フォルダ、統合報告書PDFのファイル名、行間設定を指定\n",
    "        temp_list = ['79360_アシックス_2022', 'アシックス統合報告書2022.pdf', 2]\n",
    "        df_target = pd.DataFrame([temp_list],columns=['格納フォルダ','統合報告書PDF','行間設定'])\n",
    "        #-----------------------------------------------------------------------------------------\n",
    "        #=========================================================================================\n",
    "\n",
    "    else:\n",
    "        print('Process_Modeは \"0\" または \"1\" を指定してください。')\n",
    "        return\n",
    "    \n",
    "    # 必要な列名を指定\n",
    "    folder_col = '格納フォルダ'\n",
    "    file_col = '統合報告書PDF'\n",
    "    #target_col = 'target_page'\n",
    "    line_spacing_factor_col = '行間設定'\n",
    "\n",
    "    # CSVに必要な列がなければエラー表示\n",
    "    if folder_col not in df_target.columns or file_col not in df_target.columns not in df_target.columns:\n",
    "        #print(f\"Error: CSV file must contain '{folder_col}' and '{file_col}' columns\")\n",
    "        logging.error(f\"Error: CSV file must contain '{folder_col}' and '{file_col}' columns\")\n",
    "        return\n",
    "\n",
    "    # リストの企業ごとに、pdfのテキストデータを取得・保存\n",
    "    #file_paths = []\n",
    "    for index, row in df_target.iterrows():\n",
    "\n",
    "        #================================================================\n",
    "        #前処理（フォルダの確認・パス名の定義　等）\n",
    "        folder_name = 'ir/2025/' + row[folder_col]\n",
    "        file_name = row[file_col]\n",
    "        line_spacing_factor = row[line_spacing_factor_col]\n",
    "\n",
    "        info_file_path = folder_name + '/' + 'info'\n",
    "        pdf_path = folder_name + \"/\" + file_name\n",
    "        margin_path = info_file_path  + \"/\" + \"margin.csv\"\n",
    "        multicolumn_path = info_file_path  + \"/\" + \"multicolumn.txt\"\n",
    "        # 目次見出し出力ファイルパス\n",
    "        contents_csv_path = info_file_path  + \"/\" + \"contents.csv\"\n",
    "        # 出力ファイルパス\n",
    "        output_file_path = pdf_path[:len(pdf_path)-4] + \".xml\"\n",
    "        raw_file_path = pdf_path[:len(pdf_path)-4] + \".txt\"\n",
    "\n",
    "        \n",
    "        # パスが有効かチェック\n",
    "        if pd.isna(folder_name) or pd.isna(file_name):\n",
    "            print(f\"Skipping row {index}: Folder or File is missing\")\n",
    "            logging.warning(f\"Skipping row {index}: Folder or File is missing\")\n",
    "            file_path =''\n",
    "            return\n",
    "        #属性情報を格納するフォルダ（info）の有無を確認\n",
    "        if not os.path.exists(info_file_path):\n",
    "            logging.warning(f\"Skipping row {index}: No info Folder\")\n",
    "            return\n",
    "\n",
    "        print(f\"Processing {folder_name}/{file_name}\")\n",
    "        logging.info(f\"Processing {folder_name}/{file_name}\")\n",
    "\n",
    "        # フィルタリング範囲の指定（適宜調整）\n",
    "        # 初期化 (ファイルが存在しない場合もNoneになるようにする)\n",
    "        header_y = None\n",
    "        footer_y = None\n",
    "        left_margin_x = None\n",
    "        right_margin_x = None\n",
    "\n",
    "        try:\n",
    "            # margin.csvの読み込み\n",
    "            df_margin = pd.read_csv(margin_path)\n",
    "            \n",
    "            # 変数への値の格納 (ブランクの場合はNoneに)\n",
    "            header_y = df_margin.iloc[0]['header_y'] if 'header_y' in df_margin.columns and pd.notnull(df_margin.iloc[0]['header_y']) else None\n",
    "            footer_y = df_margin.iloc[0]['footer_y'] if 'footer_y' in df_margin.columns and pd.notnull(df_margin.iloc[0]['footer_y']) else None\n",
    "            left_margin_x = df_margin.iloc[0]['left_margin_x'] if 'left_margin_x' in df_margin.columns and pd.notnull(df_margin.iloc[0]['left_margin_x']) else None\n",
    "            right_margin_x = df_margin.iloc[0]['right_margin_x'] if 'right_margin_x' in df_margin.columns and pd.notnull(df_margin.iloc[0]['right_margin_x']) else None\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            # ファイルが存在しない場合、全ての変数をNoneのままにする\n",
    "            logging.warning(f\"File 'margin.csv' is missing, default values were applied.\")\n",
    "            pass\n",
    "    \n",
    "        # 結果を確認\n",
    "        #print(f\"header_y: {header_y}\")\n",
    "        #print(f\"footer_y: {footer_y}\")\n",
    "        #print(f\"left_margin_x: {left_margin_x}\")\n",
    "        #print(f\"right_margin_x: {right_margin_x}\")\n",
    "        \n",
    "        #段組み情報を設定\n",
    "        # 段組みの閾値を x0 で設定\n",
    "        column_thresholds = []  \n",
    "        try:\n",
    "            # ファイルを開いて読み込む\n",
    "            with open(multicolumn_path, 'r', encoding='utf-8-sig') as mc_file:\n",
    "                for line in mc_file:\n",
    "                    # 各行をカンマで分割し、数値に変換してリストに格納\n",
    "                    column_thresholds.extend([float(value) for value in line.strip().split(',') if value])\n",
    "        except FileNotFoundError:\n",
    "            logging.warning(f\"File 'multicolumn.txt' is missing.\")\n",
    "            pass\n",
    "\n",
    "        except ValueError:\n",
    "            logging.warning(f\"File 'multicolumn.txt' includes non-value data.\")\n",
    "            pass\n",
    "        \n",
    "        # 読み込んだ段組み閾値情報を確認\n",
    "        #print(column_thresholds)\n",
    "    \n",
    "        # PDFファイルのオープン\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        # PDFからテキストを抽出し、ヘッダ等を除去\n",
    "        cleaned_text = {}\n",
    "        tmp_text = \"\"\n",
    "        cleaned_raw_text =\"\"\n",
    "        \n",
    "        for page_number, page in enumerate(doc, start=0):\n",
    "\n",
    "            tmp_text= clean_text_by_attributes(page, header_y, footer_y, left_margin_x, right_margin_x, column_thresholds, line_spacing_factor).encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\") + \"\\n\"\n",
    "            \n",
    "            #====================================\n",
    "            #不要な特定文字列の除去\n",
    "            #XML作成時にエラー（ExpatError: not well-formed (invalid token)）が起こる時は、raw_textから該当文字列を探して除去\n",
    "            cleaned_text[page_number +1] = re.sub(r\"[ʝ\u0007\u0001\b\u0003\u001f\u001e",
    "\u001d",
    "\u001c",
    "\u001b\u001a\u0019\u001a\u0018\u001b\u0017\u0016\u0017\u0015\u000f\u0013\u0014\u0010\u0011\u0012\u0004\u000e\u0006\f",
    "\u000b",
    "]+\", \"\", tmp_text)\n",
    "            #cleaned_text[page_number +1] = re.sub(r\"[ʝ\u0007\u0001\b\u0003\u001f\u001e",
    "\u001d",
    "\u001c",
    "\u001b\u001a\u0019\u001a\u0018\u001b\u0017\u0016\u0017\u0015\u000f\u0013\u0014\u0010\u0011\u0012\u0004\u000e\u0006\f",
    "ػମ࣌ࣄۀʢ݄ൃද࣌]+\", \"\", tmp_text)\n",
    "\n",
    "            #====================================\n",
    "            \n",
    "            cleaned_raw_text += cleaned_text[page_number +1]\n",
    "        \n",
    "        #ファイル出力\n",
    "        #テキストファイル出力：エスケープ文字を元に戻してから出力\n",
    "        cleaned_raw_text = html.unescape(cleaned_raw_text)\n",
    "        with open(raw_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_raw_text)\n",
    "        #XMLファイルを生成：エラーが出たら都度検証・対応\n",
    "        toc_mapping = load_toc_mapping(contents_csv_path)  # 目次情報を読み込み\n",
    "        tagged_data = assign_tags_from_csv(cleaned_text, toc_mapping)  # タグを適用\n",
    "        create_pretty_xml(tagged_data, output_file_path)  # XMLを生成（可読性向上）\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"処理が終了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e6d2c-0690-47f6-8d3e-c76a94e8bba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c0426-54d4-4c78-8c5a-5ab00a689dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
